{"data":"{\"post_stream\":{\"posts\":[{\"id\":3358840,\"name\":\"\",\"username\":\"ComradeHibiscus\",\"avatar_template\":\"/user_avatar/www.chiefdelphi.com/comradehibiscus/{size}/209834_2.png\",\"created_at\":\"2024-04-11T15:32:13.049Z\",\"cooked\":\"\\u003cp\\u003eHello everyone,\\u003c/p\\u003e\\n\\u003cp\\u003eI am currently working on coding field localization based on AprilTags, but I am having some issues. I output the x,y, and yaw of the resulting pose2ds to shuffleboard, and they seem very wrong. Right now, the yaw should be around 100-110 degrees, the x should be around 2.35 m, and the y should be around 6.7 m. However, the code says that the yaw is -105 degrees, the x is 1.95 m, and the y is 9.78.\\u003c/p\\u003e\\n\\u003cp\\u003eI have tried many different transformations that I found on this website, and tried to reason it out on my own by flipping around negative signs, inverting transformations, etc. but noting seem to work. Does anyone see any mistakes or steps I missed? The setup and code is as follows:\\u003c/p\\u003e\\n\\u003cp\\u003eI am using solvePnP on a coprocessor to get the relative position of the tag to the camera  and converting it to the tag to camera transformation. I then send this data over network tables for each tag as part of a string with all the tag’s information. Once the rio gets the tags as strings, it sets them up as a class and attempts to convert the transform for each tag from EDN to NWU to account for opencv and the field itself using different coordinate systems. The code for tag detection/solvepnp and the code for the AprilTagDetection class with EDN to NWU conversions is shown below.\\u003c/p\\u003e\\n\\u003cp\\u003eCoprocessor Code:\\u003c/p\\u003e\\n\\u003cpre\\u003e\\u003ccode class=\\\"lang-auto\\\"\\u003eimport time\\nimport numpy as np\\nfrom cscore import CameraServer as cs\\nfrom cscore import VideoSource as vs\\nimport cv2\\nimport robotpy_apriltag as rptag\\nfrom ntcore import NetworkTableInstance as nt\\nfrom scipy.spatial.transform import Rotation\\nimport ntcore\\n\\ninst = nt.getDefault()\\ninst.startClient4(\\\"visiontwhs\\\")\\ninst.setServerTeam(9418)\\ninst.startDSClient()\\nvision_table = inst.getTable('Vision')\\ntime.sleep(0.5)\\n\\nwidth = 640\\nheight = 480\\nfps = 15\\n\\nusb1 = cs.startAutomaticCapture(name = \\\"Launcher Cam\\\", path = \\\"/dev/v4l/by-path/platform-fd500000.pcie-pci-0000:01:00.0-usb-0:1.1:1.0-video-index0\\\")\\nusb1.setConnectionStrategy(vs.ConnectionStrategy.kConnectionKeepOpen)\\nusb1.setResolution(width, height)\\nusb1.setFPS(fps)\\n\\ntime.sleep(0.1)\\n\\noutput_stream = cs.putVideo(name = 'Cam Stream', width = width,  height = height)\\nimg = np.zeros(shape = (height, width, 3), dtype = np.uint8)\\n\\nnp.set_printoptions(suppress = True)\\n\\ndetector = rptag.AprilTagDetector()\\ndetector.addFamily(\\\"tag36h11\\\")\\n\\nDETECTION_MARGIN_THRESHOLD = 90\\n\\ntag_size = 0.1651\\nfx = 699.3778103158814\\nfy = 677.7161226393544\\ncx = 345.6059345433618\\ncy = 207.12741326228522\\n\\nintrinsics_mat = np.array(\\n    [[fx, 0, cx],\\n    [0, fy, cy],\\n    [0, 0, 1]],\\n    dtype = np.float64\\n)\\n\\ndistortions = np.array(\\n    [0.14382207979312617,\\n    -0.9851192814987014,\\n    -0.018168751047242335,\\n    0.011034504043795105,\\n    1.9833437176538498],\\n    dtype = np.float64\\n)\\n\\nt = tag_size / 2\\nobj_pts = np.array(\\n    [[-t, -t, 0],\\n    [t, -t, 0],\\n    [t, t, 0],\\n    [-t, t, 0]],\\n    dtype=np.float32\\n)\\n\\ntime.sleep(0.1)\\n\\ndef cam1TagDetect():\\n        cam1_frame_time, cam1_input_img = cam1_input_stream.grabFrame(img)\\n\\n        if cam1_frame_time == 0: # If frame time is zero then there was no time between the last frame so no new data\\n            output_stream.notifyError(cam1_input_stream.getError())\\n\\n        # Setting up tag info lists     \\n        serialized_tags_list = []\\n\\n        # Grayscale frame + detect\\n        gray_img = cv2.cvtColor(cam1_input_img, cv2.COLOR_BGR2GRAY)\\n        tag_info = detector.detect(gray_img)\\n\\n        # Filter out bad detections (low decision margin + out of bounds IDs)\\n        filter_tags = [tag for tag in tag_info if tag.getDecisionMargin() \\u0026gt; DETECTION_MARGIN_THRESHOLD]\\n        filter_tags = [tag for tag in filter_tags if ((tag.getId() \\u0026gt; 0) \\u0026amp; (tag.getId() \\u0026lt; 17))]                  \\n\\n        # Process detections\\n        for tag in filter_tags:\\n            corners = np.array(\\n                [[tag.getCorner(0).x, tag.getCorner(0).y],\\n                [tag.getCorner(1).x, tag.getCorner(1).y],\\n                [tag.getCorner(2).x, tag.getCorner(2).y],\\n                [tag.getCorner(3).x, tag.getCorner(3).y]],\\n                dtype = np.float64\\n            )\\n            # object space rotation vector and translation vector\\n            _, r_vec, t_vec = cv2.solvePnP(\\n                objectPoints = obj_pts,\\n                imagePoints = corners,\\n                cameraMatrix = np.asarray(intrinsics_mat), \\n                distCoeffs = np.asarray(distortions),\\n                flags = cv2.SOLVEPNP_SQPNP\\n            )\\n    \\n            # convert object space to camera space\\n            r_mat = cv2.Rodrigues(r_vec)[0]\\n\\n            # T = -r^T * t\\n            T_cs = -np.matrix(r_mat).T * np.matrix(t_vec)\\n            T_nt = [\\n                float(T_cs[0]),\\n                float(T_cs[1]),\\n                float(T_cs[2])\\n            ]\\n\\n            R_q = Rotation.from_matrix(r_mat).as_quat()\\n            R_nt = [\\n                float(R_q[0]),\\n                float(R_q[1]),\\n                float(R_q[2]),\\n                float(R_q[3]),\\n            ]\\n            \\n            #Serialized tag information\\n            tag_serial_string = str(tag.getId()) + \\\" \\\" + str(T_nt[0]) + \\\" \\\" + str(T_nt[1]) + \\\" \\\" + str(T_nt[2])+ \\\" \\\"\\n            tag_serial_string  += str(R_nt[0]) + \\\" \\\" + str(R_nt[1]) + \\\" \\\" + str(R_nt[2]) + \\\" \\\" + str(R_nt[3]) + \\\" \\\"\\n            tag_serial_string += str(ntcore._now())       \\n            serialized_tags_list.insert(0, tag_serial_string)\\n\\n            #pop list in case they get too big to avoid memory issues\\n            if len(serialized_tags_list) \\u0026gt; 10:\\n                serialized_tags_list.pop()\\n\\n        vision_table.putStringArray(\\\"Serialized Tags\\\", serialized_tags_list)\\n\\n\\u003c/code\\u003e\\u003c/pre\\u003e\\n\\u003cp\\u003eAprilTagDetection Class:\\u003c/p\\u003e\\n\\u003cpre\\u003e\\u003ccode class=\\\"lang-auto\\\"\\u003epackage frc.robot.subsys;\\n\\nimport edu.wpi.first.math.MatBuilder;\\nimport edu.wpi.first.math.Nat;\\nimport edu.wpi.first.math.geometry.Quaternion;\\nimport edu.wpi.first.math.geometry.Rotation3d;\\nimport edu.wpi.first.math.geometry.Transform3d;\\nimport edu.wpi.first.math.geometry.Translation3d;\\n\\npublic class AprilTagDetection {\\n    private int ID;\\n    private Transform3d transform;\\n    private double timestamp;\\n    private static Rotation3d EDN_TO_NWU = new Rotation3d(MatBuilder.fill(Nat.N3(), Nat.N3(), 0, 0, 1, -1, 0, 0, 0, -1, 0));\\n\\n    public AprilTagDetection(String serial){\\n        String[] splitSerial = serial.split(\\\" \\\");\\n\\n        ID = Integer.parseInt(splitSerial[0]);\\n\\n        Translation3d ednTrl = new Translation3d(\\n            Double.parseDouble(splitSerial[1]),\\n            Double.parseDouble(splitSerial[2]),\\n            Double.parseDouble(splitSerial[3])\\n        );\\n        Rotation3d ednRot = new Rotation3d(\\n            new Quaternion(\\n                Double.parseDouble(splitSerial[4]),\\n                Double.parseDouble(splitSerial[5]),\\n                Double.parseDouble(splitSerial[6]),\\n                Double.parseDouble(splitSerial[7])\\n            )\\n        );\\n        \\n        //Transfrom must be converted from EDN to NWU\\n        transform = new Transform3d(\\n            ednTrl.rotateBy(EDN_TO_NWU), \\n            EDN_TO_NWU.unaryMinus().plus(ednRot.plus(EDN_TO_NWU))\\n        );\\n\\n        timestamp = Double.parseDouble(splitSerial[8]);\\n    }\\n\\n    public int getID() {\\n        return ID;\\n    }\\n    \\n    public Transform3d getTransform() {\\n        return transform;\\n    }\\n\\n    public double getTimeStamp() {\\n        return timestamp;\\n    }\\n}\\n\\u003c/code\\u003e\\u003c/pre\\u003e\\n\\u003cp\\u003eThere is a separate class that recieves the tags as strings, converts them into AprilTagDetection objects, and also uses the field position of the tag and the camera to tag and camera to robot transforms to attempt to find the robot pose.\\u003c/p\\u003e\\n\\u003cp\\u003eGetting robot pose:\\u003c/p\\u003e\\n\\u003cpre\\u003e\\u003ccode class=\\\"lang-auto\\\"\\u003epackage frc.robot.subsys;\\n\\nimport java.io.IOException;\\nimport java.util.LinkedList;\\n\\nimport edu.wpi.first.apriltag.AprilTagFieldLayout;\\nimport edu.wpi.first.math.ComputerVisionUtil;\\nimport edu.wpi.first.math.geometry.Pose2d;\\nimport edu.wpi.first.math.geometry.Pose3d;\\nimport edu.wpi.first.math.geometry.Rotation3d;\\nimport edu.wpi.first.math.geometry.Transform3d;\\nimport edu.wpi.first.math.geometry.Translation3d;\\nimport edu.wpi.first.networktables.NetworkTable;\\nimport edu.wpi.first.networktables.NetworkTableInstance;\\nimport edu.wpi.first.networktables.StringArraySubscriber;\\nimport edu.wpi.first.wpilibj.smartdashboard.SmartDashboard;\\n\\npublic class VisionTablesListener {\\n    private static VisionTablesListener instance;\\n\\n    private NetworkTableInstance networkTable;\\n    private NetworkTable visionTable;\\n\\n    private StringArraySubscriber tag1Sub;\\n\\n    private Transform3d cam1Transform = new Transform3d(new Translation3d(0.3556, 0, 0.47), new Rotation3d(0, Math.toRadians(-15), 0));\\n\\n    private static LinkedList\\u0026lt;AprilTagDetection\\u0026gt; tagDetections = new LinkedList\\u0026lt;AprilTagDetection\\u0026gt;();\\n    private static AprilTagFieldLayout tagLayout;\\n\\n    private boolean tagVisible;\\n\\n    public VisionTablesListener() {\\n        networkTable = NetworkTableInstance.getDefault();\\n        visionTable = networkTable.getTable(\\\"Vision\\\");\\n\\n        tag1Sub = visionTable.getStringArrayTopic(\\\"Serialized Tags\\\").subscribe(new String[] {});\\n        try {\\n            tagLayout = AprilTagFieldLayout.loadFromResource(\\\"2024-crescendo.json\\\");\\n        } catch (IOException e) {\\n\\n        }\\n    }\\n\\n    public void putInfoOnDashboard() {\\n        if(tag1Sub.get().length \\u0026gt; 0) {\\n            tagVisible = true;\\n        } else {\\n            tagVisible = false;\\n        }\\n\\n        SmartDashboard.putBoolean(\\\"Tag in Sight\\\", tagVisible);\\n    }\\n\\n    public static VisionTablesListener getInstance() {\\n        if (instance == null)\\n            instance = new VisionTablesListener();\\n        return instance;\\n    }\\n\\n    public Pose2d[] getCam1Poses() {\\n        tagDetections.clear();\\n        String[] serializedTags = tag1Sub.get();\\n        for(String tagSerial: serializedTags) {\\n            tagDetections.add(new AprilTagDetection(tagSerial));\\n        }\\n        \\n        if(tagDetections == null || tagDetections.size() == 0)\\n            return null;\\n\\n        Pose2d[] poses = new Pose2d[tagDetections.size()];\\n        for(int i = 0; i \\u0026lt; poses.length; i++) {\\n            Pose3d tagFieldPos = tagLayout.getTagPose(tagDetections.get(i).getID()).get();         \\n            poses[i] = ComputerVisionUtil.objectToRobotPose(tagFieldPos, tagDetections.get(i).getTransform(), cam1Transform).toPose2d();\\n        }\\n        return poses;\\n    }\\n}\\n\\n\\u003c/code\\u003e\\u003c/pre\\u003e\\n\\u003cp\\u003eAny help, feedback, or solutions are greatly appreciated, thank you!\\u003c/p\\u003e\",\"post_number\":1,\"post_type\":1,\"posts_count\":2,\"updated_at\":\"2024-04-11T15:32:13.049Z\",\"reply_count\":0,\"reply_to_post_number\":null,\"quote_count\":0,\"incoming_link_count\":9,\"reads\":66,\"readers_count\":65,\"score\":53.2,\"yours\":false,\"topic_id\":462235,\"topic_slug\":\"looking-for-a-bit-of-help-with-localization-transformations\",\"display_username\":\"\",\"primary_group_name\":null,\"flair_name\":null,\"flair_url\":null,\"flair_bg_color\":null,\"flair_color\":null,\"flair_group_id\":null,\"badges_granted\":[],\"version\":1,\"can_edit\":false,\"can_delete\":false,\"can_recover\":false,\"can_see_hidden_post\":true,\"can_wiki\":false,\"read\":true,\"user_title\":null,\"bookmarked\":false,\"actions_summary\":[],\"moderator\":false,\"admin\":false,\"staff\":false,\"user_id\":62982,\"hidden\":false,\"trust_level\":1,\"deleted_at\":null,\"user_deleted\":false,\"edit_reason\":null,\"can_view_edit_history\":true,\"wiki\":false,\"user_custom_fields\":{\"user_field_4\":\"\"},\"post_url\":\"/t/looking-for-a-bit-of-help-with-localization-transformations/462235/1\",\"custom_user_title\":null,\"reactions\":[],\"current_user_reaction\":null,\"reaction_users_count\":0,\"current_user_used_main_reaction\":false,\"can_accept_answer\":false,\"can_unaccept_answer\":false,\"accepted_answer\":false,\"topic_accepted_answer\":null,\"can_vote\":false},{\"id\":3588392,\"name\":\"system\",\"username\":\"system\",\"avatar_template\":\"/uploads/default/original/4X/9/3/2/93234578e69f55873c63fc00fe2d0d85f23bce55.png\",\"created_at\":\"2025-04-11T15:32:34.195Z\",\"cooked\":\"\\u003cp\\u003eThis topic was automatically closed 365 days after the last reply. New replies are no longer allowed.\\u003c/p\\u003e\",\"post_number\":2,\"post_type\":3,\"posts_count\":2,\"updated_at\":\"2025-04-11T15:32:34.195Z\",\"reply_count\":0,\"reply_to_post_number\":null,\"quote_count\":0,\"incoming_link_count\":0,\"reads\":2,\"readers_count\":1,\"score\":0.4,\"yours\":false,\"topic_id\":462235,\"topic_slug\":\"looking-for-a-bit-of-help-with-localization-transformations\",\"display_username\":\"system\",\"primary_group_name\":null,\"flair_name\":null,\"flair_url\":null,\"flair_bg_color\":null,\"flair_color\":null,\"flair_group_id\":null,\"badges_granted\":[],\"version\":1,\"can_edit\":false,\"can_delete\":false,\"can_recover\":false,\"can_see_hidden_post\":true,\"can_wiki\":false,\"read\":true,\"user_title\":\"\",\"bookmarked\":false,\"actions_summary\":[],\"moderator\":true,\"admin\":true,\"staff\":true,\"user_id\":-1,\"hidden\":false,\"trust_level\":4,\"deleted_at\":null,\"user_deleted\":false,\"edit_reason\":null,\"can_view_edit_history\":true,\"wiki\":false,\"action_code\":\"autoclosed.enabled\",\"post_url\":\"/t/looking-for-a-bit-of-help-with-localization-transformations/462235/2\",\"custom_user_title\":null,\"reactions\":[],\"current_user_reaction\":null,\"reaction_users_count\":0,\"current_user_used_main_reaction\":false,\"can_accept_answer\":false,\"can_unaccept_answer\":false,\"accepted_answer\":false,\"topic_accepted_answer\":null}],\"stream\":[3358840,3588392]},\"timeline_lookup\":[[1,548],[2,183]],\"suggested_topics\":[{\"fancy_title\":\"Strange Wheel 180 Rotation During Autonomous with PathPlanner\",\"id\":492858,\"title\":\"Strange Wheel 180 Rotation During Autonomous with PathPlanner\",\"slug\":\"strange-wheel-180-rotation-during-autonomous-with-pathplanner\",\"posts_count\":4,\"reply_count\":2,\"highest_post_number\":4,\"image_url\":null,\"created_at\":\"2025-02-23T17:36:01.925Z\",\"last_posted_at\":\"2025-02-23T20:25:05.085Z\",\"bumped\":true,\"bumped_at\":\"2025-02-23T20:25:05.085Z\",\"archetype\":\"regular\",\"unseen\":false,\"pinned\":false,\"unpinned\":null,\"excerpt\":\"When we enable autonomous and run an auto using PathPlanner, the wheels rotate 180 before moving forward, then they rotate 180 another time at the very end of the path. The bot moves straight as it sh…\",\"visible\":true,\"closed\":false,\"archived\":false,\"bookmarked\":null,\"liked\":null,\"tags\":[],\"tags_descriptions\":{},\"like_count\":1,\"views\":95,\"category_id\":30,\"featured_link\":null,\"has_accepted_answer\":false,\"sidecar_installed\":true,\"include_dominant_colour\":false,\"topic_post_id\":3537276,\"topic_post_liked\":false,\"topic_post_can_like\":false,\"topic_post_can_unlike\":false,\"topic_post_bookmarked\":false,\"topic_post_is_current_users\":null,\"topic_post_number\":1,\"topic_post_user\":{\"id\":73620,\"username\":\"blumonster\",\"name\":\"\",\"avatar_template\":\"/letter_avatar_proxy/v4/letter/b/49beb7/{size}.png\"},\"posters\":[{\"extras\":null,\"description\":\"Original Poster\",\"user\":{\"id\":73620,\"username\":\"blumonster\",\"name\":\"\",\"avatar_template\":\"/letter_avatar_proxy/v4/letter/b/49beb7/{size}.png\",\"trust_level\":1}},{\"extras\":null,\"description\":\"Frequent Poster\",\"user\":{\"id\":54537,\"username\":\"loganbachman\",\"name\":\"Logan Bachman\",\"avatar_template\":\"/letter_avatar_proxy/v4/letter/l/f6c823/{size}.png\",\"trust_level\":2}},{\"extras\":\"latest\",\"description\":\"Most Recent Poster\",\"user\":{\"id\":28240,\"username\":\"icemannie\",\"name\":\"icemannie\",\"avatar_template\":\"/letter_avatar_proxy/v4/letter/i/bc79bd/{size}.png\",\"trust_level\":2}}]},{\"fancy_title\":\"Trouble Getting SysId Logs\",\"id\":484777,\"title\":\"Trouble Getting SysId Logs\",\"slug\":\"trouble-getting-sysid-logs\",\"posts_count\":2,\"reply_count\":0,\"highest_post_number\":2,\"image_url\":\"https://www.chiefdelphi.com/uploads/default/original/3X/f/1/f1a37995cce70072a9a82c73889cedbf1e62d4cf.jpeg\",\"created_at\":\"2025-02-02T13:33:38.344Z\",\"last_posted_at\":\"2025-02-02T14:04:02.566Z\",\"bumped\":true,\"bumped_at\":\"2025-02-02T14:04:02.566Z\",\"archetype\":\"regular\",\"unseen\":false,\"pinned\":false,\"unpinned\":null,\"excerpt\":\"Hmm… I think we just need to call SignalLogger.start() Does anyone know if passing in SignalLogger to the logging portion of the sysid routine automatically do this?\",\"visible\":true,\"closed\":false,\"archived\":false,\"bookmarked\":null,\"liked\":null,\"tags\":[],\"tags_descriptions\":{},\"like_count\":0,\"views\":169,\"category_id\":30,\"featured_link\":null,\"has_accepted_answer\":true,\"sidecar_installed\":true,\"include_dominant_colour\":false,\"topic_post_id\":3499834,\"topic_post_liked\":false,\"topic_post_can_like\":false,\"topic_post_can_unlike\":false,\"topic_post_bookmarked\":false,\"topic_post_is_current_users\":null,\"topic_post_number\":2,\"topic_post_user\":{\"id\":62175,\"username\":\"sdas\",\"name\":\"Sreyan Das\",\"avatar_template\":\"/user_avatar/www.chiefdelphi.com/sdas/{size}/267974_2.png\"},\"posters\":[{\"extras\":\"latest single\",\"description\":\"Original Poster, Most Recent Poster, Accepted Answer\",\"user\":{\"id\":62175,\"username\":\"sdas\",\"name\":\"Sreyan Das\",\"avatar_template\":\"/user_avatar/www.chiefdelphi.com/sdas/{size}/267974_2.png\",\"trust_level\":2}}]},{\"fancy_title\":\"Elevator speed\",\"id\":482750,\"title\":\"Elevator speed\",\"slug\":\"elevator-speed\",\"posts_count\":11,\"reply_count\":2,\"highest_post_number\":11,\"image_url\":null,\"created_at\":\"2025-01-20T16:47:58.130Z\",\"last_posted_at\":\"2025-01-20T22:46:23.853Z\",\"bumped\":true,\"bumped_at\":\"2025-01-20T22:46:23.853Z\",\"archetype\":\"regular\",\"unseen\":false,\"pinned\":false,\"unpinned\":null,\"excerpt\":\"We are programming an elevator, with two neo brushless, using the controller’s internal pidf, with revlib, with a 5:1 reduction, but the elevator’s movement is very slow, can anyone help us?\",\"visible\":true,\"closed\":false,\"archived\":false,\"bookmarked\":null,\"liked\":null,\"tags\":[\"robot\"],\"tags_descriptions\":{},\"like_count\":16,\"views\":903,\"category_id\":30,\"featured_link\":null,\"has_accepted_answer\":false,\"sidecar_installed\":true,\"include_dominant_colour\":false,\"topic_post_id\":3488162,\"topic_post_liked\":false,\"topic_post_can_like\":false,\"topic_post_can_unlike\":false,\"topic_post_bookmarked\":false,\"topic_post_is_current_users\":null,\"topic_post_number\":1,\"topic_post_user\":{\"id\":60531,\"username\":\"NKRY_FRC\",\"name\":\"Krypton #9487\",\"avatar_template\":\"/user_avatar/www.chiefdelphi.com/nkry_frc/{size}/206723_2.png\"},\"posters\":[{\"extras\":null,\"description\":\"Original Poster\",\"user\":{\"id\":60531,\"username\":\"NKRY_FRC\",\"name\":\"Krypton #9487\",\"avatar_template\":\"/user_avatar/www.chiefdelphi.com/nkry_frc/{size}/206723_2.png\",\"trust_level\":2}},{\"extras\":null,\"description\":\"Frequent Poster\",\"user\":{\"id\":52597,\"username\":\"Patrick3357\",\"name\":\"Patrick\",\"avatar_template\":\"/user_avatar/www.chiefdelphi.com/patrick3357/{size}/169915_2.png\",\"trust_level\":2}},{\"extras\":null,\"description\":\"Frequent Poster\",\"user\":{\"id\":19235,\"username\":\"Skyehawk\",\"name\":\"Skye Leake\",\"avatar_template\":\"/user_avatar/www.chiefdelphi.com/skyehawk/{size}/179363_2.png\",\"moderator\":true,\"trust_level\":4}},{\"extras\":null,\"description\":\"Frequent Poster\",\"user\":{\"id\":22261,\"username\":\"paulonis\",\"name\":\"paulonis\",\"avatar_template\":\"/letter_avatar_proxy/v4/letter/p/5fc32e/{size}.png\",\"trust_level\":2}},{\"extras\":\"latest\",\"description\":\"Most Recent Poster\",\"user\":{\"id\":50219,\"username\":\"Alex_Y\",\"name\":\"\",\"avatar_template\":\"/letter_avatar_proxy/v4/letter/a/82dd89/{size}.png\",\"trust_level\":2}}]},{\"fancy_title\":\"Phoenix 6 Swerve addVisionMeasurement questions\",\"id\":491766,\"title\":\"Phoenix 6 Swerve addVisionMeasurement questions\",\"slug\":\"phoenix-6-swerve-addvisionmeasurement-questions\",\"posts_count\":5,\"reply_count\":0,\"highest_post_number\":5,\"image_url\":null,\"created_at\":\"2025-02-15T01:30:01.079Z\",\"last_posted_at\":\"2025-02-26T04:20:46.362Z\",\"bumped\":true,\"bumped_at\":\"2025-02-26T04:20:46.362Z\",\"archetype\":\"regular\",\"unseen\":false,\"pinned\":false,\"unpinned\":null,\"excerpt\":\"Hello HeadMan Delphi Community, as my title states I have a few questions about these specified methods in the Phoenix 6 Swerve /** * Adds a vision measurement to the Kalman Filter.…\",\"visible\":true,\"closed\":false,\"archived\":false,\"bookmarked\":null,\"liked\":null,\"tags\":[\"vision\",\"apriltags\"],\"tags_descriptions\":{},\"like_count\":1,\"views\":276,\"category_id\":30,\"featured_link\":null,\"has_accepted_answer\":false,\"sidecar_installed\":true,\"include_dominant_colour\":false,\"topic_post_id\":3527615,\"topic_post_liked\":false,\"topic_post_can_like\":false,\"topic_post_can_unlike\":false,\"topic_post_bookmarked\":false,\"topic_post_is_current_users\":null,\"topic_post_number\":1,\"topic_post_user\":{\"id\":56270,\"username\":\"v0ncent\",\"name\":\"Vincent Banks\",\"avatar_template\":\"/user_avatar/www.chiefdelphi.com/v0ncent/{size}/258352_2.png\"},\"posters\":[{\"extras\":\"latest\",\"description\":\"Original Poster, Most Recent Poster\",\"user\":{\"id\":56270,\"username\":\"v0ncent\",\"name\":\"Vincent Banks\",\"avatar_template\":\"/user_avatar/www.chiefdelphi.com/v0ncent/{size}/258352_2.png\",\"trust_level\":2}},{\"extras\":null,\"description\":\"Frequent Poster\",\"user\":{\"id\":64292,\"username\":\"anon74528069\",\"name\":null,\"avatar_template\":\"/letter_avatar_proxy/v4/letter/a/46a35a/{size}.png\",\"trust_level\":2}},{\"extras\":null,\"description\":\"Frequent Poster\",\"user\":{\"id\":53032,\"username\":\"Traptricker\",\"name\":\"Jackson Elia\",\"avatar_template\":\"/user_avatar/www.chiefdelphi.com/traptricker/{size}/215403_2.png\",\"trust_level\":2}},{\"extras\":null,\"description\":\"Frequent Poster\",\"user\":{\"id\":24678,\"username\":\"Justin_Buist\",\"name\":\"Justin Buist\",\"avatar_template\":\"/letter_avatar_proxy/v4/letter/j/c77e96/{size}.png\",\"trust_level\":2}}]},{\"fancy_title\":\"FRC-5130 Can ID error in driver station but no error in REV Hardware Client\",\"id\":496281,\"title\":\"FRC-5130 Can ID error in driver station but no error in REV Hardware Client\",\"slug\":\"frc-5130-can-id-error-in-driver-station-but-no-error-in-rev-hardware-client\",\"posts_count\":2,\"reply_count\":0,\"highest_post_number\":2,\"image_url\":\"https://www.chiefdelphi.com/uploads/default/optimized/3X/b/6/b6b5c198cc2535548a3bcf62c1597a82e13b374d_2_1024x546.png\",\"created_at\":\"2025-03-20T00:51:10.150Z\",\"last_posted_at\":\"2025-03-20T01:04:03.416Z\",\"bumped\":true,\"bumped_at\":\"2025-03-20T01:04:03.416Z\",\"archetype\":\"regular\",\"unseen\":false,\"pinned\":false,\"unpinned\":null,\"excerpt\":\"Hello we are currently scrambling trying to fix this error after we were running our practice field and coral fell and struck our electrical plate, primarily our Robo Rio. after this hit the driver st…\",\"visible\":true,\"closed\":false,\"archived\":false,\"bookmarked\":null,\"liked\":null,\"tags\":[\"robot\",\"frc\",\"2025\",\"reefscape\",\"firstsouthcarolina\",\"southcarolina\"],\"tags_descriptions\":{},\"like_count\":1,\"views\":53,\"category_id\":30,\"featured_link\":null,\"has_accepted_answer\":false,\"sidecar_installed\":true,\"include_dominant_colour\":false,\"topic_post_id\":3562507,\"topic_post_liked\":false,\"topic_post_can_like\":false,\"topic_post_can_unlike\":false,\"topic_post_bookmarked\":false,\"topic_post_is_current_users\":null,\"topic_post_number\":1,\"topic_post_user\":{\"id\":57662,\"username\":\"Programming5130\",\"name\":\"\",\"avatar_template\":\"/letter_avatar_proxy/v4/letter/p/4da419/{size}.png\"},\"posters\":[{\"extras\":null,\"description\":\"Original Poster\",\"user\":{\"id\":57662,\"username\":\"Programming5130\",\"name\":\"\",\"avatar_template\":\"/letter_avatar_proxy/v4/letter/p/4da419/{size}.png\",\"trust_level\":1}},{\"extras\":\"latest\",\"description\":\"Most Recent Poster\",\"user\":{\"id\":37435,\"username\":\"beedward\",\"name\":\"Ben Edwards\",\"avatar_template\":\"/user_avatar/www.chiefdelphi.com/beedward/{size}/111315_2.png\",\"trust_level\":2}}]}],\"tags\":[\"robot\"],\"tags_descriptions\":{},\"fancy_title\":\"Looking for a bit of help with localization transformations\",\"id\":462235,\"title\":\"Looking for a bit of help with localization transformations\",\"posts_count\":2,\"created_at\":\"2024-04-11T15:32:12.979Z\",\"views\":159,\"reply_count\":0,\"like_count\":0,\"last_posted_at\":\"2025-04-11T15:32:34.195Z\",\"visible\":true,\"closed\":true,\"archived\":false,\"has_summary\":false,\"archetype\":\"regular\",\"slug\":\"looking-for-a-bit-of-help-with-localization-transformations\",\"category_id\":30,\"word_count\":1220,\"deleted_at\":null,\"user_id\":62982,\"featured_link\":null,\"pinned_globally\":false,\"pinned_at\":null,\"pinned_until\":null,\"image_url\":null,\"slow_mode_seconds\":0,\"draft\":null,\"draft_key\":\"topic_462235\",\"draft_sequence\":null,\"unpinned\":null,\"pinned\":false,\"current_post_number\":1,\"highest_post_number\":2,\"deleted_by\":null,\"actions_summary\":[{\"id\":4,\"count\":0,\"hidden\":false,\"can_act\":false},{\"id\":8,\"count\":0,\"hidden\":false,\"can_act\":false},{\"id\":10,\"count\":0,\"hidden\":false,\"can_act\":false},{\"id\":7,\"count\":0,\"hidden\":false,\"can_act\":false}],\"chunk_size\":20,\"bookmarked\":false,\"topic_timer\":null,\"message_bus_last_id\":0,\"participant_count\":1,\"show_read_indicator\":false,\"thumbnails\":null,\"slow_mode_enabled_until\":null,\"valid_reactions\":[\"heart\",\"laughing\",\"point_up\",\"+1\",\"-1\",\"100\",\"open_mouth\",\"cry\",\"question\",\"thinking\",\"call_me_hand\",\"hugs\",\"angry\"],\"user_chosen_thumbnail_url\":null,\"sidecar_installed\":true,\"can_vote\":false,\"vote_count\":0,\"user_voted\":false,\"discourse_zendesk_plugin_zendesk_id\":null,\"discourse_zendesk_plugin_zendesk_url\":\"https://your-url.zendesk.com/agent/tickets/\",\"details\":{\"can_edit\":false,\"notification_level\":1,\"participants\":[{\"id\":62982,\"username\":\"ComradeHibiscus\",\"name\":\"\",\"avatar_template\":\"/user_avatar/www.chiefdelphi.com/comradehibiscus/{size}/209834_2.png\",\"post_count\":1,\"primary_group_name\":null,\"flair_name\":null,\"flair_url\":null,\"flair_color\":null,\"flair_bg_color\":null,\"flair_group_id\":null,\"trust_level\":1}],\"created_by\":{\"id\":62982,\"username\":\"ComradeHibiscus\",\"name\":\"\",\"avatar_template\":\"/user_avatar/www.chiefdelphi.com/comradehibiscus/{size}/209834_2.png\"},\"last_poster\":{\"id\":-1,\"username\":\"system\",\"name\":\"system\",\"avatar_template\":\"/uploads/default/original/4X/9/3/2/93234578e69f55873c63fc00fe2d0d85f23bce55.png\"}},\"bookmarks\":[]}"}
